{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CtH75gfazCq"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UmMWuow5eCj",
        "outputId": "81da9667-93f3-49ae-cb8f-84c4c30f39f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "#Install python3.9 first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY9XGIWhTDlI",
        "outputId": "6203fb0b-6dd0-4a6f-b304-d94e24e5e164"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget https://svn.spraakdata.gu.se/sb-arkiv/pub/dalaj/datasetDaLAJsplit.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cpMVuMXZUeGX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: numpy>=1.22.4; python_version < \"3.11\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Eman\\Downloads\\Thesis\\.venv_3.9\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
            "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Eman\\Downloads\\Thesis\\.venv_3.9\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.5.2-cp39-cp39-win_amd64.whl (11.0 MB)\n",
            "Collecting joblib>=1.2.0\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Collecting threadpoolctl>=3.1.0\n",
            "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Collecting scipy>=1.6.0\n",
            "  Downloading scipy-1.13.1-cp39-cp39-win_amd64.whl (46.2 MB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
            "Installing collected packages: joblib, threadpoolctl, scipy, scikit-learn\n",
            "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.13.1 threadpoolctl-3.5.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VRyFdCgvT5bv"
      },
      "outputs": [],
      "source": [
        "dalaj_df = pd.read_csv(\"./content/datasetDaLAJsplit.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "Z9SI5HsXT-X9"
      },
      "outputs": [],
      "source": [
        "#@title Fix arrangement Train\n",
        "\n",
        "train_df = dalaj_df[dalaj_df['split'] == \"train\" ]\n",
        "\n",
        "sorted_items = []\n",
        "for idx, item in train_df.iterrows():\n",
        "  correct_dict = {\"Text\": item[\"corrected sentence\"],\"Label\":1}\n",
        "  sorted_items.append(correct_dict)\n",
        "\n",
        "  incorrect_dict = {\"Text\": item[\"original sentence\"],\"Label\":0}\n",
        "  sorted_items.append(incorrect_dict)\n",
        "\n",
        "final_train_df = pd.DataFrame(sorted_items)\n",
        "from sklearn.utils import shuffle\n",
        "final_train_df = shuffle(final_train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "vEpFBLrPqMup",
        "outputId": "4c2af545-385f-4cff-e2a8-654df9c8e29b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1974</th>\n",
              "      <td>Människor här är jättesnälla .</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3673</th>\n",
              "      <td>Det är viktigt för mig att klädföretag tar ett...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4566</th>\n",
              "      <td>Temat familj finns ju med olika slutsatser och...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1593</th>\n",
              "      <td>När mamman åt kakan förändrades hon till en bj...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5118</th>\n",
              "      <td>Ständig utveckling i livet och utifrån behoven...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>687</th>\n",
              "      <td>Jag tycker om C-svensk-stad för att min familj...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2919</th>\n",
              "      <td>Demokratin är ett verktyg till att göra ett sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2080</th>\n",
              "      <td>Dessutom finns det många studenter på SFI , oc...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2222</th>\n",
              "      <td>Det är jättestort och det finns ett kafé där ,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2944</th>\n",
              "      <td>Pappan och andra mäktiga personer , som är fli...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7682 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  Label\n",
              "1974                     Människor här är jättesnälla .      1\n",
              "3673  Det är viktigt för mig att klädföretag tar ett...      0\n",
              "4566  Temat familj finns ju med olika slutsatser och...      1\n",
              "1593  När mamman åt kakan förändrades hon till en bj...      0\n",
              "5118  Ständig utveckling i livet och utifrån behoven...      1\n",
              "...                                                 ...    ...\n",
              "687   Jag tycker om C-svensk-stad för att min familj...      0\n",
              "2919  Demokratin är ett verktyg till att göra ett sa...      0\n",
              "2080  Dessutom finns det många studenter på SFI , oc...      1\n",
              "2222  Det är jättestort och det finns ett kafé där ,...      1\n",
              "2944  Pappan och andra mäktiga personer , som är fli...      1\n",
              "\n",
              "[7682 rows x 2 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "AF6ANETnU-ZC"
      },
      "outputs": [],
      "source": [
        "#@title Fix arrangement for test\n",
        "\n",
        "test_df = dalaj_df[dalaj_df['split'] == \"test\" ]\n",
        "\n",
        "sorted_items = []\n",
        "for idx, item in test_df.iterrows():\n",
        "  correct_dict = {\"Text\": item[\"corrected sentence\"],\"Label\":1}\n",
        "  sorted_items.append(correct_dict)\n",
        "\n",
        "  incorrect_dict = {\"Text\": item[\"original sentence\"],\"Label\":0}\n",
        "  sorted_items.append(incorrect_dict)\n",
        "\n",
        "final_test_df = pd.DataFrame(sorted_items)\n",
        "from sklearn.utils import shuffle\n",
        "final_test_df = shuffle(final_test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zclE-BjWVCw3",
        "outputId": "639c8353-bbea-48f0-ff33-da76f2f37982"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>745</th>\n",
              "      <td>Det kan vara kroppsspråk men främst sker det g...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>Då uppstår frågan om jag ska ta ett extra pass...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>Kan du bjuda hem arbetskamraterna för att fika...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>789</th>\n",
              "      <td>Men denna definition stämmer inte ständigt nuf...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>827</th>\n",
              "      <td>Man kan känna sig bättre eftersom båda män och...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>587</th>\n",
              "      <td>För det andra promenerar jag ofta i parken ell...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>Varje person i detta samhälle har rätt att bo ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>Kan du bjuda hem arbetskamraterna för att fika...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>Mammorna tog mer ansvar för familjen , och pap...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>För pojkarna var det tufft att använda alla ve...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>888 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  Label\n",
              "745  Det kan vara kroppsspråk men främst sker det g...      0\n",
              "458  Då uppstår frågan om jag ska ta ett extra pass...      1\n",
              "554  Kan du bjuda hem arbetskamraterna för att fika...      1\n",
              "789  Men denna definition stämmer inte ständigt nuf...      0\n",
              "827  Man kan känna sig bättre eftersom båda män och...      0\n",
              "..                                                 ...    ...\n",
              "587  För det andra promenerar jag ofta i parken ell...      0\n",
              "499  Varje person i detta samhälle har rätt att bo ...      0\n",
              "558  Kan du bjuda hem arbetskamraterna för att fika...      1\n",
              "878  Mammorna tog mer ansvar för familjen , och pap...      1\n",
              "472  För pojkarna var det tufft att använda alla ve...      1\n",
              "\n",
              "[888 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "srh8jiuSU4lM"
      },
      "outputs": [],
      "source": [
        "#@title sentence model\n",
        "#!pip install -U sentence-transformers\n",
        "#from sentence_transformers import SentenceTransformer, models\n",
        "\n",
        "#model_dir = 'Peltarion/xlm-roberta-longformer-base-4096'\n",
        "#mod = \"KB/bert-base-swedish-cased\"\n",
        "#sen_xlmr = \"sentence-transformers/paraphrase-xlm-r-multilingual-v1\"\n",
        "\n",
        "#word_embedding_model = models.Transformer(mod, tokenizer_name_or_path= mod , max_seq_length=512)\n",
        "#pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "\n",
        "#model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWv9suyZftF9"
      },
      "source": [
        "#EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "mRqv7ZfGcZst"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'swe_aug' already exists and is not an empty directory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk==3.7 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from -r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: spacy==3.2.4 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from -r requirements.txt (line 2)) (3.2.4)\n",
            "Requirement already satisfied: spacy-legacy==3.0.9 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from -r requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: spacy-loggers==1.0.2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from -r requirements.txt (line 4)) (1.0.2)\n",
            "Requirement already satisfied: spacy-udpipe==1.0.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from -r requirements.txt (line 5)) (1.0.0)\n",
            "Collecting gensim==3.8.1\n",
            "  Using cached gensim-3.8.1.tar.gz (23.4 MB)\n",
            "Requirement already satisfied: ipykernel in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from -r requirements.txt (line 7)) (6.29.5)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from -r requirements.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: numpy==1.26.4 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from -r requirements.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: pydantic==1.7.4 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from -r requirements.txt (line 10)) (1.7.4)\n",
            "Requirement already satisfied: scipy==1.10.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from -r requirements.txt (line 11)) (1.10.1)\n",
            "Requirement already satisfied: joblib in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from nltk==3.7->-r requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from nltk==3.7->-r requirements.txt (line 1)) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from nltk==3.7->-r requirements.txt (line 1)) (4.66.5)\n",
            "Requirement already satisfied: click in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from nltk==3.7->-r requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: setuptools in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (49.2.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (2.0.10)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (8.0.17)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (3.1.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (1.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (3.0.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (0.11.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (0.4.2)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (24.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (2.0.8)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (0.7.11)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy==3.2.4->-r requirements.txt (line 2)) (2.4.8)\n",
            "Requirement already satisfied: ufal.udpipe>=1.2.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from spacy-udpipe==1.0.0->-r requirements.txt (line 5)) (1.3.1.1)\n",
            "Requirement already satisfied: six>=1.5.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from gensim==3.8.1->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from gensim==3.8.1->-r requirements.txt (line 6)) (7.0.4)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (5.7.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (1.8.5)\n",
            "Requirement already satisfied: pyzmq>=24 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (26.2.0)\n",
            "Requirement already satisfied: comm>=0.1.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (0.2.2)\n",
            "Requirement already satisfied: nest-asyncio in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (8.6.3)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (5.14.3)\n",
            "Requirement already satisfied: psutil in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (6.0.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (0.1.7)\n",
            "Requirement already satisfied: tornado>=6.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (6.4.1)\n",
            "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipykernel->-r requirements.txt (line 7)) (8.18.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from tqdm->nltk==3.7->-r requirements.txt (line 1)) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from jinja2->spacy==3.2.4->-r requirements.txt (line 2)) (2.1.5)\n",
            "Requirement already satisfied: pathlib-abc==0.1.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from pathy>=0.3.5->spacy==3.2.4->-r requirements.txt (line 2)) (0.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4->-r requirements.txt (line 2)) (2024.8.30)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy==3.2.4->-r requirements.txt (line 2)) (2.2.3)\n",
            "Requirement already satisfied: language-data>=1.2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.2.4->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: wrapt in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from smart_open>=1.8.1->gensim==3.8.1->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 7)) (4.3.6)\n",
            "Requirement already satisfied: pywin32>=300; sys_platform == \"win32\" and platform_python_implementation != \"PyPy\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 7)) (306)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3; python_version < \"3.10\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 7)) (8.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 7)) (2.9.0.post0)\n",
            "Requirement already satisfied: exceptiongroup; python_version < \"3.11\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (1.2.2)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (3.0.47)\n",
            "Requirement already satisfied: stack-data in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.6.3)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: decorator in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (5.1.1)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.10\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (4.12.2)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.19.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.2.4->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from importlib-metadata>=4.8.3; python_version < \"3.10\"->jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 7)) (3.20.2)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.2.13)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.1.0)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.2.3)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (2.4.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 7)) (0.8.4)\n",
            "Using legacy 'setup.py install' for gensim, since package 'wheel' is not installed.\n",
            "Installing collected packages: gensim\n",
            "    Running setup.py install for gensim: started\n",
            "    Running setup.py install for gensim: finished with status 'done'\n",
            "Successfully installed gensim-3.8.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\Eman\\Downloads\\Thesis\\.venv_3.9\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n",
            "'bzip2' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'type'>\n",
            "Downloaded pre-trained UDPipe model for 'sv' language\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Eman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Construct the absolute path using the current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "#@title EDA\n",
        "!git clone https://github.com/mosh98/swe_aug.git\n",
        "%pip install -r requirements.txt\n",
        "\"\"\" if cant install because of access denied: https://stackoverflow.com/questions/64278198/error-can-not-perform-a-user-install-user-site-packages-are-not-visible-in \"\"\"\n",
        "!wget https://www.ida.liu.se/divisions/hcs/nlplab/swectors/swectors-300dim.txt.bz2\n",
        "!bzip2 -dk /content/swectors-300dim.txt.bz2\n",
        "\n",
        "\n",
        "word_vec_path = os.path.join(current_dir, \"content\", \"swectors-300dim.txt\")\n",
        "\n",
        "\"\"\" word_vec_path = \"./content/swectors-300dim.txt\" \"\"\"\n",
        "\n",
        "from swe_aug import EDA\n",
        "print(type(EDA.Enkel_Data_Augmentation)) #for debugging purposes\n",
        "aug = EDA.Enkel_Data_Augmentation(word_vec_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HKlFNOlfkuq"
      },
      "source": [
        "# Fraction of Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: requests in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from transformers) (24.1)\n",
            "Collecting huggingface-hub<1.0,>=0.23.2\n",
            "  Downloading huggingface_hub-0.25.0-py3-none-any.whl (436 kB)\n",
            "Collecting tokenizers<0.20,>=0.19\n",
            "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from transformers) (2024.9.11)\n",
            "Collecting safetensors>=0.4.1\n",
            "  Downloading safetensors-0.4.5-cp39-none-win_amd64.whl (286 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Collecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Installing collected packages: fsspec, pyyaml, filelock, huggingface-hub, tokenizers, safetensors, transformers\n",
            "Successfully installed filelock-3.16.1 fsspec-2024.9.0 huggingface-hub-0.25.0 pyyaml-6.0.2 safetensors-0.4.5 tokenizers-0.19.1 transformers-4.44.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting MultiEncoder==0.0.6\n",
            "  Using cached MultiEncoder-0.0.6-py3-none-any.whl (3.8 kB)\n",
            "Installing collected packages: MultiEncoder\n",
            "Successfully installed MultiEncoder-0.0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipywidgets"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
            "Collecting widgetsnbextension~=4.0.12\n",
            "  Using cached widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipywidgets) (8.18.1)\n",
            "Collecting jupyterlab-widgets~=3.0.12\n",
            "  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
            "Requirement already satisfied: exceptiongroup; python_version < \"3.11\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
            "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
            "Requirement already satisfied: decorator in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.10\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
            "Requirement already satisfied: stack-data in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
            "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
            "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
            "Collecting torch\n",
            "  Downloading torch-2.4.1-cp39-cp39-win_amd64.whl (199.3 MB)\n",
            "Requirement already satisfied: filelock in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from torch) (4.12.2)\n",
            "Collecting networkx\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from torch) (3.1.4)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Collecting mpmath<1.4,>=1.1.0\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: networkx, mpmath, sympy, torch\n",
            "Successfully installed mpmath-1.3.0 networkx-3.2.1 sympy-1.13.3 torch-2.4.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.98-py3-none-any.whl (873 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ultralytics) (2.2.3)\n",
            "Requirement already satisfied: psutil in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ultralytics) (6.0.0)\n",
            "Collecting py-cpuinfo\n",
            "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting matplotlib>=3.3.0\n",
            "  Downloading matplotlib-3.9.2-cp39-cp39-win_amd64.whl (7.8 MB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ultralytics) (4.66.5)\n",
            "Collecting seaborn>=0.11.0\n",
            "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Collecting pillow>=7.1.2\n",
            "  Downloading pillow-10.4.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
            "Collecting ultralytics-thop>=2.0.0\n",
            "  Downloading ultralytics_thop-2.0.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests>=2.23.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ultralytics) (2.4.1)\n",
            "Collecting torchvision>=0.9.0\n",
            "  Downloading torchvision-0.19.1-cp39-cp39-win_amd64.whl (1.3 MB)\n",
            "Collecting opencv-python>=4.6.0\n",
            "  Using cached opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from ultralytics) (1.10.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Collecting cycler>=0.10\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.3.0-cp39-cp39-win_amd64.whl (211 kB)\n",
            "Collecting importlib-resources>=3.2.0; python_version < \"3.10\"\n",
            "  Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Collecting pyparsing>=2.3.1\n",
            "  Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "Collecting kiwisolver>=1.3.1\n",
            "  Downloading kiwisolver-1.4.7-cp39-cp39-win_amd64.whl (55 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.53.1-cp39-cp39-win_amd64.whl (2.2 MB)\n",
            "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: networkx in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: sympy in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.1.4->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib>=3.3.0->ultralytics) (3.20.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: py-cpuinfo, cycler, contourpy, importlib-resources, pyparsing, pillow, kiwisolver, fonttools, matplotlib, seaborn, ultralytics-thop, torchvision, opencv-python, ultralytics\n",
            "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.53.1 importlib-resources-6.4.5 kiwisolver-1.4.7 matplotlib-3.9.2 opencv-python-4.10.0.84 pillow-10.4.0 py-cpuinfo-9.0.0 pyparsing-3.1.4 seaborn-0.13.2 torchvision-0.19.1 ultralytics-8.2.98 ultralytics-thop-2.0.6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'c:\\users\\eman\\downloads\\thesis\\.venv_3.9\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install MultiEncoder==0.0.6\n",
        "!pip install ipywidgets\n",
        "!pip install torch\n",
        "!pip install ultralytics\n",
        "#https://stackoverflow.com/questions/78114412/import-torch-how-to-fix-oserror-winerror-126-error-loading-fbgemm-dll-or-depen (if theres an error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "W_w2j7PNPOK1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ],
      "source": [
        "mod = \"KB/bert-base-swedish-cased\"\n",
        "from mle import multi_layer_encoder\n",
        "le = multi_layer_encoder.multi_layer_encoder(mod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cellView": "form",
        "id": "-Sr5gZetf1mF"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def frac(dataframe, fraction,label):\n",
        "    \"\"\"Returns fraction of data\"\"\"\n",
        "    if fraction == 1.0:\n",
        "      return dataframe\n",
        "      \n",
        "    y = dataframe[label]\n",
        "    train, test = train_test_split(dataframe,train_size=fraction,stratify = y)\n",
        "    \n",
        "    return train\n",
        "\n",
        "def encode_df(dataframe, mod=None,col = \"text\"):\n",
        "  encoded = []\n",
        "  for idx, item in dataframe.iterrows():\n",
        "        list_of_encoded_inputs, dect = le.multi_encode(item.Text)\n",
        "        encoded.append(list_of_encoded_inputs[1])\n",
        "        #encoded.append(model.encode(item[col])) \n",
        "\n",
        "  return encoded\n",
        "\n",
        "\n",
        "reports = [] #clf_report (Before Augment, After Augment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr9Yj46tqlCw",
        "outputId": "4bfba69d-7dcc-40ba-c519-f6865f5e577e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "test_embed = []\n",
        "\n",
        "y_test = final_test_df.Label\n",
        "\n",
        "for idx, item in final_test_df.iterrows():\n",
        "      list_of_encoded_inputs, dect = le.multi_encode(item.Text)\n",
        "      test_embed.append(list_of_encoded_inputs[1])\n",
        "#test_embed.append(model.encode(item.Text))\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kr3mxNL0fJY",
        "outputId": "4b2152ee-af43-4b8d-cf7e-93e50ce80428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting SpaceAugmentation\n",
            "  Downloading SpaceAugmentation-0.0.2-py3-none-any.whl (4.6 kB)\n",
            "Installing collected packages: SpaceAugmentation\n",
            "Successfully installed SpaceAugmentation-0.0.2\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "#from swe_aug.Other_Techniques import Text_Cropping\n",
        "#frag = Text_Cropping.cropper(percent = 0.25)\n",
        "!pip install SpaceAugmentation\n",
        "from aug import Augmentation\n",
        "\n",
        "ag = Augmentation.Augmentation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x7wWhJTZ2xA",
        "outputId": "b87dc599-5de1-4ca0-9b4b-c3931b98ece6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Already downloaded a model for the 'sv' language\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Eman\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "from swe_aug.Other_Techniques import Type_SR\n",
        "aug = Type_SR.type_DA(word_vec_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qU1sg9wXgtMf",
        "outputId": "566b67af-04e0-4d0a-eebf-ed959ecd7c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "______________________________________________\n",
            "Percentage 10\n",
            "Before Augmentation size:  (768, 2)\n",
            "Before Augmentation\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.87      0.66       444\n",
            "           1       0.63      0.22      0.33       444\n",
            "\n",
            "    accuracy                           0.55       888\n",
            "   macro avg       0.58      0.55      0.49       888\n",
            "weighted avg       0.58      0.55      0.49       888\n",
            "\n",
            " \n",
            "After Augmentation size:  1536\n",
            "After Augmentation\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.75      0.64       444\n",
            "           1       0.62      0.42      0.50       444\n",
            "\n",
            "    accuracy                           0.58       888\n",
            "   macro avg       0.59      0.58      0.57       888\n",
            "weighted avg       0.59      0.58      0.57       888\n",
            "\n",
            "______________________________________________\n",
            "______________________________________________\n",
            "Percentage 20\n",
            "Before Augmentation size:  (1536, 2)\n",
            "Before Augmentation\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.51      0.55       444\n",
            "           1       0.58      0.67      0.62       444\n",
            "\n",
            "    accuracy                           0.59       888\n",
            "   macro avg       0.59      0.59      0.59       888\n",
            "weighted avg       0.59      0.59      0.59       888\n",
            "\n",
            " \n",
            "After Augmentation size:  3072\n",
            "After Augmentation\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.27      0.39       444\n",
            "           1       0.54      0.87      0.67       444\n",
            "\n",
            "    accuracy                           0.57       888\n",
            "   macro avg       0.61      0.57      0.53       888\n",
            "weighted avg       0.61      0.57      0.53       888\n",
            "\n",
            "______________________________________________\n",
            "______________________________________________\n",
            "Percentage 30\n",
            "Before Augmentation size:  (2304, 2)\n",
            "Before Augmentation\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.41      0.50       444\n",
            "           1       0.57      0.77      0.65       444\n",
            "\n",
            "    accuracy                           0.59       888\n",
            "   macro avg       0.60      0.59      0.57       888\n",
            "weighted avg       0.60      0.59      0.57       888\n",
            "\n",
            " \n",
            "After Augmentation size:  4608\n",
            "After Augmentation\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.59      0.60       444\n",
            "           1       0.60      0.63      0.61       444\n",
            "\n",
            "    accuracy                           0.61       888\n",
            "   macro avg       0.61      0.61      0.61       888\n",
            "weighted avg       0.61      0.61      0.61       888\n",
            "\n",
            "______________________________________________\n",
            "______________________________________________\n",
            "Percentage 40\n",
            "Before Augmentation size:  (3072, 2)\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m y_train \u001b[38;5;241m=\u001b[39m temp_train_df\u001b[38;5;241m.\u001b[39mLabel\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBefore Augmentation size: \u001b[39m\u001b[38;5;124m\"\u001b[39m,temp_train_df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 18\u001b[0m train_embed \u001b[38;5;241m=\u001b[39m \u001b[43mencode_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_train_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mText\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m logreg \u001b[38;5;241m=\u001b[39m SGDClassifier(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3000\u001b[39m,n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m logreg\u001b[38;5;241m.\u001b[39mfit(train_embed, y_train)\n",
            "Cell \u001b[1;32mIn[13], line 19\u001b[0m, in \u001b[0;36mencode_df\u001b[1;34m(dataframe, mod, col)\u001b[0m\n\u001b[0;32m     17\u001b[0m encoded \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, item \u001b[38;5;129;01min\u001b[39;00m dataframe\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 19\u001b[0m       list_of_encoded_inputs, dect \u001b[38;5;241m=\u001b[39m \u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mText\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m       encoded\u001b[38;5;241m.\u001b[39mappend(list_of_encoded_inputs[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     21\u001b[0m       \u001b[38;5;66;03m#encoded.append(model.encode(item[col])) \u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\mle\\multi_layer_encoder.py:93\u001b[0m, in \u001b[0;36mmulti_layer_encoder.multi_encode\u001b[1;34m(self, input_text, encode_layers, max_pool)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmulti_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_text, encode_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, max_pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     84\u001b[0m \u001b[38;5;250m     \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m     Encode a text with the longformer model.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m     :param input_text: The text to encode.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m     :rtype: list, dict\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m     \"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m      model_output, encoded_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_encoded_longformer_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m      dect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_last_six_hidden(model_output\u001b[38;5;241m.\u001b[39mhidden_states, encode_layers)\n\u001b[0;32m     96\u001b[0m      list_of_encoded_inputs \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# starts from encoder_layers to last year 12 in the model.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\mle\\multi_layer_encoder.py:78\u001b[0m, in \u001b[0;36mmulti_layer_encoder.get_encoded_longformer_input\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Compute token embeddings\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 78\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_input)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_output, encoded_input\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1141\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1141\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1153\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1154\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:694\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    683\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    684\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    685\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m         output_attentions,\n\u001b[0;32m    692\u001b[0m     )\n\u001b[0;32m    693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:626\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    623\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    624\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 626\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    629\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\transformers\\pytorch_utils.py:239\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    638\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 639\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:551\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 551\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    552\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    553\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Training Loop\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "split_percentage = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "\n",
        "label = \"Label\"\n",
        "\n",
        "for percentage in split_percentage:\n",
        "    print(\"______________________________________________\")\n",
        "    \n",
        "    print(\"Percentage\",percentage)\n",
        "    \n",
        "    temp_train_df = frac(final_train_df, percentage/100,label)\n",
        "    y_train = temp_train_df.Label\n",
        "    \n",
        "    print(\"Before Augmentation size: \",temp_train_df.shape)\n",
        "    \n",
        "    train_embed = encode_df( temp_train_df,  col=\"Text\")\n",
        "\n",
        "    logreg = SGDClassifier(max_iter=3000,n_jobs=-1)\n",
        "    logreg.fit(train_embed, y_train)\n",
        "    \n",
        "    y_pred = logreg.predict(test_embed)\n",
        "    \n",
        "    r_1 = classification_report(y_test, y_pred)\n",
        "    print(\"Before Augmentation\")\n",
        "    print(r_1)\n",
        "    print(\" \")\n",
        "\n",
        "    # picking out bad samples\n",
        "    incorrect_df = temp_train_df[temp_train_df['Label'] == 0]\n",
        "\n",
        "    #Augmentation\n",
        "\n",
        "    aug_samples = []\n",
        "    for idx, item in incorrect_df.iterrows():\n",
        "      txt = item.Text\n",
        "      lab = item.Label\n",
        "      list_of_augs = aug.type_synonym_sr(txt, token_type = \"NOUN\", n = 2)\n",
        "      \n",
        "      for element in list_of_augs:\n",
        "          aug_samples.append({\"Text\":' '.join(element),\"Label\":lab})\n",
        "\n",
        "    \n",
        "    new_aug_samples = pd.DataFrame(aug_samples)\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    new_df = pd.concat([temp_train_df,new_aug_samples],ignore_index=True)\n",
        "    \n",
        "    print(\"After Augmentation size: \",new_df.shape[0])\n",
        "\n",
        "\n",
        "    #augmented train test\n",
        "\n",
        "    #encode\n",
        "    train_embed = encode_df( new_df,  col=\"Text\")\n",
        "    y_train = new_df.Label\n",
        "    \n",
        "    logreg_ = SGDClassifier(max_iter=3000, n_jobs=-1)\n",
        "    logreg_.fit(train_embed, y_train)\n",
        "\n",
        "    y_pred = logreg_.predict(test_embed)\n",
        "\n",
        "\n",
        "    r_2 = classification_report(y_test, y_pred)\n",
        "    print(\"After Augmentation\")\n",
        "    print(r_2)\n",
        "\n",
        "    #save the reports\n",
        "    reports.append((percentage, r_1,r_2))\n",
        "\n",
        "\n",
        "\n",
        "    print(\"______________________________________________\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9akuWLUTxQOw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "Requirement already satisfied: scipy in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from sentence-transformers) (0.24.6)\n",
            "Requirement already satisfied: Pillow in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: tqdm in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: requests in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: sympy in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: networkx in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.7.24)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\eman\\downloads\\text_aug_low_res-main\\text_aug_low_res-main\\.venv\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-3.0.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52e234250fe64ea78e2c8193c4657669",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Eman\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-xlm-r-multilingual-v1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f5fd79405e94238a5ce4f470cbe4034",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f5f261838ac46fb9735804bde9d286c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/550 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06407db881e44759930cf77c3dbb0bba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6b2ce9ac7ff84f0889995995cab85366",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf71e6fea2c645eab6dfb05c380ff7e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Eman\\Downloads\\Text_Aug_Low_Res-main\\Text_Aug_Low_Res-main\\.venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -U sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer, models\n",
        "\n",
        "#model_dir = 'Peltarion/xlm-roberta-longformer-base-4096'\n",
        "#mod = \"KB/bert-base-swedish-cased\"\n",
        "sen_xlmr = \"sentence-transformers/paraphrase-xlm-r-multilingual-v1\"\n",
        "\n",
        "word_embedding_model = models.Transformer(sen_xlmr, tokenizer_name_or_path= sen_xlmr , max_seq_length=512)\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gwsA7fUxc-D1"
      },
      "outputs": [],
      "source": [
        "    # picking out bad samples\n",
        "incorrect_df = final_train_df[final_train_df['Label'] == 0]\n",
        "\n",
        "    #Augmentation\n",
        "\n",
        "aug_samples = []\n",
        "original_augmented = [] #every element : orginal_text, (Tuple of augmented sentences)\n",
        "for idx, item in incorrect_df.iterrows():\n",
        "      txt = item.Text\n",
        "      lab = item.Label\n",
        "      list_of_augs = aug.type_synonym_sr(txt, token_type = \"NOUN\", n = 2)\n",
        "      \n",
        "      temp_list = []\n",
        "      for element in list_of_augs:\n",
        "            aug_samples.append({\"Text\":' '.join(element),\"Label\":lab})\n",
        "            temp_list.append(' '.join(element))\n",
        "      \n",
        "      original_augmented.append((txt,temp_list))\n",
        "\n",
        "    \n",
        "\n",
        "new_aug_samples = pd.DataFrame(aug_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "bRQKDOMPxJ7Y"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "\n",
        "def checkSimilarity(reference_string, list_of_strings, model):\n",
        "    \"\"\"\n",
        "    This function takes a reference string and a list of strings and returns a list of strings that are similar to the reference string.\n",
        "\n",
        "    :param reference_string:\n",
        "    :param list_of_strings:\n",
        "    :param model: sentence transformer model\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    #1. Encode using Sentence Transformer\n",
        "    #2. Calculate cosine similarity\n",
        "    #3. Append the similirty value to the list\n",
        "    # caclulcate percentage of elements below 0.9\n",
        "    # return the list, and the percentage of elements below 0.9\n",
        "\n",
        "    reference_encoded = model.encode(reference_string,convert_to_numpy=True) #encoded reference string\n",
        "    list_of_cosine_similarity = []\n",
        "    for string in list_of_strings:\n",
        "        #print(string)\n",
        "        encoded_string = model.encode(string,convert_to_numpy=True)\n",
        "\n",
        "        #find coside similairity of enocded String and reference string\n",
        "        similarity = util.cos_sim(reference_encoded, encoded_string)\n",
        "        list_of_cosine_similarity.append(similarity.item())\n",
        "    #print(list_of_cosine_similarity)\n",
        "    #sum(i > 5 for i in j)\n",
        "    percentage_of_elements_below_0_9 = sum(i < 0.9 for i in list_of_cosine_similarity) / len(list_of_cosine_similarity)\n",
        "\n",
        "    return sum(i < 0.95 for i in list_of_cosine_similarity),percentage_of_elements_below_0_9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fCnYlgH62Cq9"
      },
      "outputs": [],
      "source": [
        "low_semantic_sentences = []\n",
        "for item in original_augmented:\n",
        "  num, percentage = checkSimilarity(item[0],item[1],model)\n",
        "  low_semantic_sentences.append(num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhUhqsjL4Ufe",
        "outputId": "2c2722b1-22d4-4484-c209-95d873d2daf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Sentences: 3841\n",
            "Num of Augmented Sentences: 7682\n"
          ]
        }
      ],
      "source": [
        "print(\"Original Sentences:\",len(original_augmented))\n",
        "print(\"Num of Augmented Sentences:\",len(original_augmented)*2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzn0rs1z5yjZ",
        "outputId": "9cafca69-4b6f-47bc-d2e2-5aca5f33e8b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of Bad Augmented Sentences: 2797\n"
          ]
        }
      ],
      "source": [
        "print(\"Num of Bad Augmented Sentences:\",sum(low_semantic_sentences))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlioqFao68Ir",
        "outputId": "57ef47c4-8b59-4b71-c6a8-5ecb6d35ed3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of Bad Augmented Sentences: 36.40978911741734\n"
          ]
        }
      ],
      "source": [
        "num_of_aug_samples = len(original_augmented)*2\n",
        "print(\"Percentage of Bad Augmented Sentences:\",(sum(low_semantic_sentences)/num_of_aug_samples)*100)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMR+5rF1P4fbAqNkJG2Gnot",
      "collapsed_sections": [],
      "mount_file_id": "1uipmJSZ1bfmh-ovt5KIQ0X-tqFJ-rgNq",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
